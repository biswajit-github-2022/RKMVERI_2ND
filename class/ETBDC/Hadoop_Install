export CLASSPATH="$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.1.jar:$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.1.jar:$HADOOP_HOME/share/hadoop/common/hadoop-common-3.3.1.jar:~/MapReduceTutorial/SalesCountry/*:$HADOOP_HOME/lib/*"

javac -d . SalesMapper.java SalesCountryReducer.java SalesCountryDriver.java
jar cfm ProductSalePerCountry.jar Manifest.txt SalesCountry/*.class

$HADOOP_HOME/bin/hdfs dfs -copyFromLocal SalesJan2009.csv /

$HADOOP_HOME/bin/hadoop jar ProductSalePerCountry.jar /SalesJan2009.csv /mapreduce_output_sales

$HADOOP_HOME/bin/hdfs dfs -cat /mapreduce_output_sales/part-00000


sudo addgroup hadoop_
sudo adduser --ingroup hadoop_ hduser_
sudo adduser hduser_ sudo
su - hduser_
ssh-keygen -t rsa -P ""
cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
ssh localhost
exit
sudo apt-get purge openssh-server
sudo apt-get install openssh-server

wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz
sudo tar xzf hadoop-3.3.1.tar.gz
sudo mv hadoop-3.3.1 hadoop
sudo chown -R hduser_:hadoop_ hadoop


vi ~/.bashrc 
#Set HADOOP_HOME
export HADOOP_HOME=<Installation Directory of Hadoop>
#Set JAVA_HOME
export JAVA_HOME=<Installation Directory of Java>
# Add bin/ directory of Hadoop to PATH
export PATH=$PATH:$HADOOP_HOME/bin

source ~/.bashrc

vi $HADOOP_HOME/etc/hadoop/hadoop-env.sh
export JAVA_HOME=path before bin


vi $HADOOP_HOME/etc/hadoop/core-site.xml
<property>
<name>hadoop.tmp.dir</name>
<value>/app/hadoop/tmp</value>
<description>Parent directory for other temporary directories.</description>
</property>
<property>
<name>fs.defaultFS </name>
<value>hdfs://localhost:54310</value>
<description>The name of the default file system. </description>
</property>


sudo chown -R hduser_:Hadoop_ <Path of Directory created in above step>
sudo chmod 750 <Path of Directory created in above step>

vi $HADOOP_HOME/etc/hadoop/mapred-site.xml
<property>
<name>mapreduce.jobtracker.address</name>
<value>localhost:54311</value>
<description>MapReduce job tracker runs at this host and port.
</description>
</property>

vi $HADOOP_HOME/etc/hadoop/hdfs-site.xml
<property>
<name>dfs.replication</name>
<value>1</value>
<description>Default block replication.</description>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>/home/hduser_/hdfs</value>
</property>


sudo mkdir -p /home/hduser_/hdfs

sudo chown -R hduser_:hadoop_ /home/hduser_/hdfs
sudo chmod 750 /home/hduser_/hdfs

$HADOOP_HOME/bin/hdfs namenode -format

$HADOOP_HOME/sbin/start-dfs.sh

$HADOOP_HOME/sbin/start-yarn.sh

jps


















sudo apt update
sudo apt install default-jre
sudo apt install default-jdk
javac -version
java -version

